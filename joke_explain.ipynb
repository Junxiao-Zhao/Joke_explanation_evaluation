{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import regex as re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "from accelerate import init_empty_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"theblackcat102/joke_explaination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcd97ca47c842a694e0661a393fcb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/377 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.filter(lambda x: x['joke'].startswith('Q:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c511bab92ae34c6c979259f7be336e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "245175"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].to_csv('./data/jokes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df = pd.read_csv('./data/jokes.csv')\n",
    "explain_df = pd.read_csv('./data/gpt4turbo_explained_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df['explaination'] = explain_df['Explanation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df.to_csv('./data/jokes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df = jokes_df.sample(60)\n",
    "select_ds = Dataset.from_pandas(select_df).train_test_split(test_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_index = np.random.choice(range(len(dataset['train'])), size=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_ds = dataset['train'].select(sampled_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760117b346a24200a960232a791da7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_ds = selected_ds.filter(lambda x: x['joke'].startswith('Q:'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f595a18421b4ca8992e3b239cc9d244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "42102"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ds.to_csv('./data/jokes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_ds = selected_ds.train_test_split(test_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee42a3d5f9545069d852f06462fc962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3373c43b596412187506e9a47402054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "27319"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_ds = select_ds.remove_columns(['__index_level_0__'])\n",
    "select_ds['train'].to_csv('./data/train.csv')\n",
    "select_ds['test'].to_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df = pd.read_csv('./data/jokes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "eval_df = pd.read_csv('./data/eval-Llama2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program\\miniconda3\\envs\\DL\\lib\\site-packages\\pyarrow\\pandas_compat.py:358: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "eval_ds = Dataset.from_pandas(eval_df[['joke', 'explaination']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program\\miniconda3\\envs\\DL\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    trust_remote_code=True,\n",
    "    use_safetensors=True,\n",
    ")\n",
    "quan_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\",\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18c39eb00d34e9b9a76ac66d1169008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True,\n",
    "    use_safetensors=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quan_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-shot\n",
    "prompt = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a joke explainer.\n",
    "\n",
    "Each input joke contains a question and an answer. Your job is to explain why the answer together with the question forms a joke. Use no more than 3-4 sentences to explain the joke. Do not add \"Ah I see\" or similar terms to your explanation.\n",
    "<</SYS>>\n",
    "%s[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e346bb806743a092358ee3fe2da1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_ds = select_ds['test']\n",
    "eval_ds = eval_ds.map(lambda x: {'prompt': prompt % x['joke']},\n",
    "                      remove_columns=['url', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-shot\n",
    "prompt = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a joke explainer.\n",
    "\n",
    "Each input joke contains a question and an answer. Your job is to explain why the answer together with the question forms a joke.\n",
    "\n",
    "Here are some examples of joke explanations:\n",
    "Joke: Q: Why didn't the string ever win a race? A: It always tied!\n",
    "Explanation: The joke plays on the double meaning of the word 'tied.' In one sense, 'tied' means to finish a race at the same time as another competitor, resulting in a draw. In another sense, 'tied' refers to the action of tying a knot. Since the subject of the joke is a 'string,' the humor arises from imagining the string as always tying itself into knots, which humorously explains why it could never win a race.\n",
    "\n",
    "Use no more than 3-4 sentences to explain the joke. Do not add \"Ah I see\" or similar terms to your explanation.\n",
    "<</SYS>>\n",
    "%s[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# five-shot\n",
    "prompt = \"\"\"<s>[INST] <<SYS>>\n",
    "You are a joke explainer.\n",
    "\n",
    "Each input joke contains a question and an answer. Your job is to explain why the answer together with the question forms a joke.\n",
    "\n",
    "Here are some examples of joke explanations:\n",
    "1.\n",
    "Joke: Q: Why didn't the string ever win a race? A: It always tied!\n",
    "Explanation: The joke plays on the double meaning of the word 'tied.' In one sense, 'tied' means to finish a race at the same time as another competitor, resulting in a draw. In another sense, 'tied' refers to the action of tying a knot. Since the subject of the joke is a 'string,' the humor arises from imagining the string as always tying itself into knots, which humorously explains why it could never win a race.\n",
    "2.\n",
    "Joke: Q: Why did the golfer wear two pairs of pants? A: In case he got a hole in one!\n",
    "Explanation: This joke plays on the double meaning of the phrase 'hole in one'. In golf, 'a hole in one' refers to a player hitting the ball directly from the tee into the hole with one stroke, which is a very good outcome. However, in the context of wearing pants, 'a hole in one' humorously suggests a literal hole in one of the pairs of pants. Thus, the golfer wearing two pairs of pants is a silly precaution to ensure he still has one intact pair if one gets a hole.\n",
    "3.\n",
    "Joke: Q:What do prisoners use to call each other? A:Cell phones!\n",
    "Explanation: The joke plays on the double meaning of the word 'cell.' In one sense, a 'cell' is a small room where prisoners are kept, and in another sense, it refers to 'cellular phones,' commonly known as cell phones. The humor arises from the pun created by using 'cell phones' to imply that prisoners would use phones related to their incarceration cells to communicate.\n",
    "4.\n",
    "Joke: Q: What kind of shoes does a ninja wear? A: Sneakers!\n",
    "Explanation: The joke plays on the word 'sneakers' which is a type of shoe known for being comfortable and quiet, ideal for casual wear. However, in the context of the joke, 'sneakers' also refers to the ability to sneak around silently, which is a stereotypical attribute of a ninja. Thus, the humor arises from the double meaning of 'sneakers' as both a type of shoe and a description of a ninja's stealthy behavior.\n",
    "5.\n",
    "Joke: Q: Why did Cinderella get kicked off the soccer team? A: Because she ran away from the ball!\n",
    "Explanation: The joke plays on the double meaning of the word 'ball'. In the context of the story of Cinderella, 'ball' refers to the formal dance she attends, from which she famously runs away at midnight. In the context of soccer, 'ball' refers to the soccer ball, which players should not run away from if they want to play effectively. The humor arises from the absurdity of applying the fairy tale behavior to the soccer field, creating a funny and unexpected reason for Cinderella to be kicked off the team.\n",
    "\n",
    "Use no more than 3-4 sentences to explain the joke. Do not add \"Ah I see\" or similar terms to your explanation.\n",
    "<</SYS>>\n",
    "%s[/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9322c3a7a08b4cf5909a963ae15b6e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_ds = eval_ds.map(lambda x: {'prompt': prompt % x['joke']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assist_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = assist_pipeline(KeyDataset(eval_ds, 'prompt'),\n",
    "                          do_sample=True,\n",
    "                          top_k=10,\n",
    "                          num_return_sequences=1,\n",
    "                          eos_token_id=tokenizer.eos_token_id,\n",
    "                          max_length=1000,\n",
    "                          return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_ls = []\n",
    "for res in results:\n",
    "    ans_ls.append(re.sub(r'\\s+', ' ', res[0]['generated_text']).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df['five-shot'] = ans_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.to_csv('./data/eval-Llama2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds = eval_ds.add_column('zero-shot', ans_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ds = eval_ds.remove_columns(['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9418b9205e2344b39433d4e96678ac91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "42727"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds.to_csv('./data/eval-Llama2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_explain = functools.partial(assist_pipeline,\n",
    "                                do_sample=True,\n",
    "                                top_k=10,\n",
    "                                num_return_sequences=1,\n",
    "                                eos_token_id=tokenizer.eos_token_id,\n",
    "                                max_length=300,\n",
    "                                return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df['Llama-2-7b-chat-hf_explanation'] = jokes_df['joke'].apply(\n",
    "    lambda x: get_explain(prompt % x)[0]['generated_text'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df[['joke', 'Llama-2-7b-chat-hf_explanation'\n",
    "          ]].to_csv('./data/jokes_llama2_explained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jokes_df.to_csv('./data/jokes_llama2_explained.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke = \"Q: Why did the two 4s decide to skip dinner? A: Because they already 8.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program\\miniconda3\\envs\\DL\\lib\\site-packages\\transformers\\pipelines\\base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The joke works because the question \"Why did the two 4s decide to skip dinner?\" implies that there are two identical numbers, \"4,\" which are having a decision-making conversation. The punchline, \"Because they already 8,\" is unexpected and creates humor by revealing that the two \"4s\" are actually two different numbers, not the same one, which is the expected answer to the question.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_explain(prompt % joke)[0]['generated_text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = assist_pipeline(\n",
    "    prompt % joke,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=200,\n",
    "    return_full_text=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, I see! The joke here is a play on words. The question asks \"Why did the two 4s decide to skip dinner?\" implying that there are two numbers, both of which are equal to 4. However, the answer is \"Because they already 8,\" which is a pun on the number 8, as it sounds like \"ate.\" So the punchline is that the two 4s didn't need to eat dinner because they already ate 8, which is a clever play on words.\n"
     ]
    }
   ],
   "source": [
    "print(sequences[0]['generated_text'].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, I see! The joke is a play on words. The question \"Why did the two 4s decide to skip dinner?\" is asking why two numbers, both of which are equal to 4, would decide to skip dinner. The answer \"Because they already 8\" is a pun, as the number 8 is a multiple of 4. So, the joke is that the two 4s are already \"8\" (meaning they are equal to 8), so they don\\'t need to skip dinner. It\\'s a simple but clever"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
